---
author: Martin Trapp
title: Pólya tree processes (part 1)
date: 2023-01-03
tags: 
  - BNP
  - Pólya trees
math: true
---

Welcome to the first more "technical" post.
In this post, I will have a look at the Pólya tree process and look at some basic properties of it.
I believe this is an excellent topic for a first technical post, as it combines many research directions I am very excited about.
In particular, Pólya trees provide a principled way of specifying a Bayesian nonparametric prior over arbitrary[^1] probability distributions (i.e., the complexity of the generated distribution is dependent on the data complexity) while at the same time having a *closed-form* posterior and allowing tractable inferences of moments.


## Preliminaries
In order to be somewhat rigorous, I will briefly introduce some basic notation. 
Let \\((X, \mathcal{A})\\) be a measurable space with sample space \\(X\\) and a suitable sigma-algebra[^2] \\(\mathcal{A}\\) on \\(X\\) (e.g., the Borel algebra if \\(X\\) is a topological space).
See [[1]](#1) or [[2]](#2) for details.
Next, we equip the space with a probability measure, that is, a function \\(\mathbb{P} \colon \mathcal{A} \to [0,1]\\) assigning each "event" \\(A \in \mathcal{A}\\) some probability value. As usually done, we will assume that \\(\mathbb{P}\\) is an additive set function, i.e. \\(\mathbb{P}(A \cup B) = \mathbb{P}(A) + \mathbb{P}(B)\\), and that the probability of \\(X\\) is one. 

## Pólya tree process
In Pólya trees (e.g., [[3]](#3), [[4]](#4)) we are concerned with generating \\(\Bbb{P}\\) in a *constructive* way.
Loosely speaking, Pólya tree processes define a generative process that constructs a probability measure recursively.
Historically, these processes have been investigated in the search for a family of processes that is more flexible than the Dirichlet process, whose draws are almost surely discrete.
Interestingly the Pólya tree processes can generate discrete and continuous distributions depending on their parameterisation. 
In the broader context, Pólya tree processes are a special case of trailfree processes [[4]](#4).

In the Pólya tree process, we first recursively partition the sample space \\(X\\) into dyadic partitions, i.e.,
$$
\begin{aligned}
\Pi^0 &= \lbrace X \rbrace = \lbrace A_0 \cup A_1 \rbrace \\\
\Pi^1 &= \lbrace A_0, A_1 \rbrace = \lbrace A_{00} \cup A_{01}, A_{10} \cup A_{11} \rbrace \\\
\Pi^2 &= \lbrace A_{00}, A_{01}, A_{10}, A_{11} \rbrace \\\
&= \lbrace A_{000} \cup A_{001}, A_{010} \cup A_{011}, A_{100} \cup A_{101}, A_{110} \cup A_{111} \rbrace \\\
&\vdots \\\
\Pi^j &= \lbrace A_{\epsilon0} \cup A_{\epsilon1} \mid \epsilon \in \lbrace 0,1\rbrace^j \rbrace \\\
&\vdots \\\
\end{aligned}
$$
which continues infinitely and can be visualised as a tree:
{{< figure src="../figures/2023_01_polya/figure1.svg" alt="Illustration of a recursive partitioning" >}}

Next, we associate each set \\(A\\) in the tree with a conditional probability \\(\theta(A)\\) following an independent beta distribution \\(\text{Beta}(\alpha(A_{\epsilon0}), \alpha(A_{\epsilon1}))\\).
Note that I am using \\(\alpha(A)\\) to denote the parameters of the beta distribution as a function of \\(A\\).
By following the described generative processes, we are *constructing* a random probability measure with sigma-algebra generated by the partition tree.

### Example
As an example, let the sample space be given as \\(X = (0,1] ]\\) and let us partition the sample space recursively by cutting each sub-space in the middle.
Then we obtain, 
$$
\begin{aligned}
\Pi^0 &= \lbrace X \rbrace &=& \lbrace (0,1] \rbrace \\\
\Pi^1 &= \lbrace A_0, A_1 \rbrace &=& \lbrace (0,\frac{1}{2}], (\frac{1}{2},1] \rbrace \\\
\Pi^2 &= \lbrace A_{00}, A_{01}, A_{10}, A_{11} \rbrace &=& \lbrace (0,\frac{1}{4}], (\frac{1}{4},\frac{2}{4}], (\frac{2}{4},\frac{3}{4}], (\frac{3}{4},1] \rbrace \\\
&\vdots
\end{aligned}
$$

In practice, we truncate the Pólya tree processes to a finite depth. For example, Hanson [[6]](#6) suggested truncating the tree based on the number of observations heuristically.
In a future post, I will discuss truncations and the implications of truncating a Pólya tree process in detail.
For now, let us assume that we truncate the process at depth \\(J=2\\), i.e., we obtain a tree with \\(2^J = 4\\) leaves and \\(\frac{2^{J+1} - 2}{2} = 3\\) parameters where we assume that \\(\theta(A_{\epsilon0}) \sim \text{Beta}\\) and \\(\theta(A_{\epsilon1}) = 1 - \theta(A_{\epsilon0})\\). Then, given draws for each \\(\theta(A_{\epsilon0})\\), the probability \\(\Bbb{P}(A)\\) is given by the product of conditional probabilities / variables on the path from the root to \\(A\\), for example, the probability of \\(A_{010}\\) is:
$$
\Bbb{P}(A_{010}) = \theta(A_0) \theta(A_{01}) \theta(A_{010}) = \theta(A_0) (1 -\theta(A_{00})) \theta(A_{010}) .
$$


### Inference
The **cool** thing about Pólya trees is that posterior inference essentially boils down to *counting*, as we can leverage the conjugacy of the beta-binomial experiment to perform exact inference. Meaning the posterior for each \\(\theta(A)\\) is simply:
$$
\theta(A_\epsilon) \mid x_1, \ldots, x_n \sim \text{Beta}(\alpha(A_{\epsilon0}) + n(A_{\epsilon0}), \alpha(A_{\epsilon1}) + n(A_{\epsilon1})) \tag{1}
$$
where \\(n(A)\\) denotes the number of observations in \\(A\\).
This nice and simple form is one of the attractive properties of Pólya trees compared to other nonparametric priors over continuous distributions.

### Properties
We can influence the properties of the Pólya tree by changing the behaviour of the beta parameters.
A common choice is to tie the parameters for each level and let them only depend on the depth.
By doing so, one can enforce discreteness of the random probability measure under certain choices of \\(\alpha\\) [[5]](#5) and obtain the *Dirichlet process* as a special case when choosing: [[4]](#4)
$$
\alpha(A_\epsilon) = 2^{-|\epsilon|} . \tag{2}
$$
Below is a random draw from the posterior of a Pólya tree process truncated to a depth of 10 levels conditioned on observations drawn from a mixture of Gaussians (dashed lines) with \\(\alpha\\) set as in Eq. (2).
{{< figure src="../figures/2023_01_polya/figure2_1.svg" alt="Random posterior draws" >}}

Another popular choice is to ensure that \\(\Bbb{P}\\) has a density wrt to the Lebesgue measure. This can achieved by choosing:
$$
\alpha(A_\epsilon) = |\epsilon| 2^{2 |\epsilon| \gamma} , \tag{3}
$$

where \\(0 < \gamma < 1\\) [[7]](#7), resulting in an optimal minimax convergence rate for estimating an assumed density (wrt supremum norm). I refer to [[7]](#7) for details.
The figure below illustrates two random draws from the posterior (solid and dash-dotted) using Eq. (3) with \\(\gamma = 0.3\\) on the same data as before.
{{< figure src="../figures/2023_01_polya/figure2_2.svg" alt="Random posterior draws" >}}

Even though the generated density functions look reasonable, they are not very smooth in part due to the independence assumption made in the prior processes.
A common way to overcome the challenges in obtaining smooth continuous density functions is to use a mixture of Pólya trees [[6]](#6). An alternative strategy is to introduce additional latent variables [[8]](#8).
Another drawback is that the dyadic points (we assumed them to always be in the middle for now) play a crucial role in the posterior of a truncated tree. In fact, it might be preferable to adjust the dyadic tree to the data, e.g., by using a mixture of different dyadic trees.

Further note that, for now, we have always assumed that \\(\alpha\\) is tied for each level. However, in practice, one might want to vary the shape parameters depending on the data complexity. Ma [[8]](#8) proposed an interesting perspective on the precision parameters of the beta priors as *shrinkage parameters*. This perspective stems from the observation that the posterior mean can be decomposed into a weighted average of the prior mean and the proportion of probability mass assigned to region A. This shrinkage away from the prior mean in the posterior is controlled by the prior variance, hence, the name shrinkage parameter.
I will discuss this approach and other recent advancements to scale Pólya trees to higher dimensional data in the next post on Pólya trees.

### Relationship to Probabilistic Circuits
Somewhat surprisingly, Pólya trees are related to probabilistic circuits, a family of tractable probabilistic models that has recently gained increasing attention.
In a preliminary study, we have shown [[9]](#9) that certain constructions[^3] of Bayesian probabilistic circuits (probabilistic circuits with Bayesian priors on their parameters) are truncated Pólya tree processes in disguise. 


## Codes to reproduce the plots
The code below illustrates how to implement Pólya trees for 1D data in Julia and uses a parametric family as centring distribution, as suggested in [[5]](#5).
Note that the implementation is fairly simple, and computing densities under a J-level truncated Pólya tree process is \\(\mathcal{O}(J)\\).

<details>
<summary>Julia code</summary>

```Julia
using Distributions, StatsBase, LogarithmicNumbers

# map obervation to A in jth layer
kfun(x::AbstractFloat, j::Int, base::Distribution) = min(floor(Int, 2^j * cdf(base, x)) + 1, 2^j)

# count observations in each A
ns(x::AbstractVector, J::Int; base = Uniform(0,1)) = map(j -> counts(kfun.(x, j, base), 1:2^j), 1:J)

# draw conditional probabilities
function thetas(n::Vector{Vector{Int}}; α = 1, ρ = (j) -> 2.0^(-j))
    θs = map(layer -> begin
                 j, nj = layer
                 m = reshape(nj, 2, 2^(j-1))
                 θl = map(i -> ULogarithmic.(rand(Beta( α * ρ(j) .+ m[:,i]...))), 1:2^(j-1))
                 mapreduce(θ -> [θ, one(θ) - θ], vcat, θl)
            end, enumerate(n))
    return θs
end

# compute probabilities
prob(x, θs, base) = mapreduce( ((j, θ),) -> θ[kfun.(x, j, base)], (a,b) -> a .* b, enumerate(θs) )

probmf(x, θs, base) = prob(x, θs, base)
probdf(x, θs, base) = 2^J * prob(x, θs, base) .* pdf.(base, x)

Random.seed!(123)
mix = MixtureModel([Normal(-1,0.1), Normal(1, 0.5)], [0.2, 0.8])
x = rand(mix, 100)

minx, maxx = minimum(x)-1, maximum(x)+1
base = Uniform(minx, maxx)

J = 10

n = ns(x, J; base = base)

# Figure 1
xtest = range(minimum(x) - 1, maximum(x) + 1, length=500)
ytest = probmf(xtest, thetas(n; ρ = (j) -> 2.0^(-j)), base)

# Figure 2
xtest = range(minimum(x) - 1, maximum(x) + 1, length=500)
ytest1 = probdf(xtest, thetas(n, ρ = (j) -> j*2.0^(2*j*0.3)), base)
ytest2 = probdf(xtest, thetas(n, ρ = (j) -> j*2.0^(2*j*0.3)), base)

```

</details>


--- 

## References
<a id="1">[1]</a> René Schilling. 
*Measures, Integrals and Martingales.*
Cambridge University Press, 2005.
</br>
<a id="2">[2]</a> Terence Tao.
*An Introduction to Measure Theory.* 
American Mathematical Society, 2011.
</br>
<a id="3">[3]</a> Michael Lavine. 
*Some aspects of Pólya tree distributions for statistical modelling.*
The Annals of Statistics, 20(3):1222–1235, 1992.
</br>
<a id="4">[4]</a> Thomas S. Ferguson.
*Prior Distributions on Spaces of Probability Measures.*
Annals of Statistics, 2(4):615-629, 1974. 
</br>
<a id="5">[5]</a> David Blackwell.
*Discreteness of Ferguson Selections.*
Annals of Statistics, 1(2):356-358, 1973. 
</br>
<a id="6">[6]</a> Timothy E Hanson.
*Inference for Mixtures of Finite Pólya Tree Models.*
Journal of the American Statistical Association, 101(476):1548-1565, 2006.
</br>
<a id="7">[7]</a> Ismaël Castillo 
*Pólya tree posterior distributions on densities.*
Annales de l'Institut Henri Poincaré, Probabilités et Statistiques, 53(4), 2017.
</br>
<a id="8">[8]</a> Li Ma.
*Adaptive Shrinkage in Pólya Tree Type Models.*
Bayesian Analysis, 12(3), 2017.
</br>
<a id="9">[9]</a> Martin Trapp and Arno Solin.
*On Priors in Bayesian Probabilistic Circuits and Multivariate Pólya Trees.*
Preliminary results presented at , 2022.

[^1]: Arbitrary is somewhat of an overstatement. The family of distributions is limited to those having discontinuous probability measures. However, extensions of Pólya trees (such as mixtures) can generate a larger family. It might be interesting to characterise the families of distributions that various extensions of Pólya trees can generate.
[^2]: It is optional to know what a sigma-algebra is to follow the post. In short, think of a collection of sub-sets of \\(X\\) that we want to measure. This collection must follow some rules, i.e., it needs to contain the empty set and the set \\(X\\), and has to be closed under finite unions and complements.
[^3]: These constructions are rather common in the literature.
