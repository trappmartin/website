+++
author = "Martin Trapp"
mainSections = [""]
+++

### News
- Together with colleagues, I co-organized the 7th Workshop on [Tractable Probabilistic Modeling](https://tractable-probabilistic-modeling.github.io/tpm2024/) at UAI 2024!
- I am visiting the Department of Statistics at the University of British Columbia for two month.
- Together with colleagues, I co-organized the 2nd Workshop on [Uncertainty Quantification for Computer Vision](https://uncv2023.github.io/) at ICCV 2023!
<!-- - Together with colleagues, I co-organized the 6th Workshop on [Tractable Probabilistic Modeling](https://tractable-probabilistic-modeling.github.io/tpm2023/) at UAI 2023!
- I started a blog with research notes! -->

---

<br/>

### Short Bio
I am an [Academy of Finland](https://www.aka.fi/en/) postdoctoral researcher in the Department of Computer Science at [Aalto University](https://www.aalto.fi/en), Finland, and a member of the [ELLIS](https://ellis.eu/) society.
My research is centered around **uncertainty quantification** with a particular interest on **tractability, principled approaches, and large-scale settings** with applications in deep learning.
I conduct research torgheter with many amazing colleagues & collaborators and closely work with the team of my postdoc advisor [Arno Solin](https://users.aalto.fi/~asolin/).

Before joining Aalto, I completed my PhD at Graz University of Technology, Austria, under the supervision of [Franz Pernkopf](https://www.spsc.tugraz.at/people/franz-pernkopf.html) and [Robert Peharz](https://robert-peharz.github.io/). 
During my PhD I was a research assistant at the [Austrian Research Institute for AI](https://www.ofai.at/) and at the [Computational and Biological Learning lab](https://www.cbl-cambridge.org/) of the University of Cambridge, UK, where I worked on [Turing.jl](https://turinglang.org/).
I finished my master's degree at the Vienna University of Technology and was a research assistant at [VRVis](https://www.vrvis.at/) at the same time.

<br/>

### Research Interests
I am broadly interested in probabilistic machine learning with a particular interest in efficient uncertainty quantification and ways to utilize tractable inference to establish more trustworthy machine learning. Currently, I am particularly excited about the following research questions:

- How can we quantify uncertainties efficiently and effectively in the case of large-scale systems?
- What are the limits of tractable yet expressive models and how can we push this frontier?
- How can we identify and encode function-space priors and constraints in deep learning models?

Moreover, I am particularly interested in how we can utilize probabilistic (and causal) reasoning to build more reliable machine learning systems.

<br/>

### Scientific Activities
I have been involved in the organization of the following workshops: Uncertainty Quantification in Computer Vision ([2024](https://uncv2024.github.io/), [2023](https://uncv2023.github.io/), [2022](https://uncv2022.github.io/)), and Tractable Probabilistic Modeling ([2024](https://tractable-probabilistic-modeling.github.io/tpm2024/), [2023](https://tractable-probabilistic-modeling.github.io/tpm2023/), [2022](https://tractable-probabilistic-modeling.github.io/tpm2022/)).
Moreover, I helped in organizing the [Nordic Probabilistic AI School 2022](https://probabilistic.ai/) and actively organize the ELLIS Seminar on [Advances in Probabilistic Machine Learning (APML)](https://aaltoml.github.io/apml/) at Aalto University.

<br/>

### Selected References

1. L. Loconte et al. [Subtractive Mixture Models via Squaring: Representation and Learning](https://arxiv.org/abs/2310.00724), <i>International Conference on Learning Representations (ICLR)</i>, 2024.
2. Z. Yu, <u>M. Trapp</u>, K. Kersting. [Characteristic Circuits](https://nips.cc/virtual/2023/poster/72798), <i>Advances in Neural Information Processing Systems (NeurIPS)</i>, 2023.
3. L. Meronen, <u>M. Trapp</u>, A. Solin. [Periodic Activation Functions Induce Stationarity](https://arxiv.org/abs/2110.13572), <i>Advances in Neural Information Processing Systems (NeurIPS)</i>, 2021.
4. <u>M. Trapp</u> et al. [Bayesian Learning of Sum-Product Networks](https://arxiv.org/abs/1905.10884), <i>Advances in Neural Information Processing Systems (NeurIPS)</i>, 2019.
5. <u>M. Trapp</u>. [Sum-Product Networks for Complex Modelling Scenarios](https://diglib.tugraz.at/download.php?id=61541b71cfbb0&location=browse), <i>PhD thesis</i>, 2020.
